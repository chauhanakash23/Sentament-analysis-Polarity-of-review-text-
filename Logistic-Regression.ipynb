{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Fine Food Reviews Analysis\n",
    "\n",
    "\n",
    "Data Source: https://www.kaggle.com/snap/amazon-fine-food-reviews <br>\n",
    "\n",
    "EDA: https://nycdatascience.com/blog/student-works/amazon-fine-foods-visualization/\n",
    "\n",
    "\n",
    "The Amazon Fine Food Reviews dataset consists of reviews of fine foods from Amazon.<br>\n",
    "\n",
    "Number of reviews: 568,454<br>\n",
    "Number of users: 256,059<br>\n",
    "Number of products: 74,258<br>\n",
    "Timespan: Oct 1999 - Oct 2012<br>\n",
    "Number of Attributes/Columns in data: 10 \n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1. Id\n",
    "2. ProductId - unique identifier for the product\n",
    "3. UserId - unqiue identifier for the user\n",
    "4. ProfileName\n",
    "5. HelpfulnessNumerator - number of users who found the review helpful\n",
    "6. HelpfulnessDenominator - number of users who indicated whether they found the review helpful or not\n",
    "7. Score - rating between 1 and 5\n",
    "8. Time - timestamp for the review\n",
    "9. Summary - brief summary of the review\n",
    "10. Text - text of the review\n",
    "\n",
    "\n",
    "#### Objective:\n",
    "Given a review, determine whether the review is positive (rating of 4 or 5) or negative (rating of 1 or 2).\n",
    "\n",
    "<br>\n",
    "[Q] How to determine if a review is positive or negative?<br>\n",
    "<br> \n",
    "[Ans] We could use Score/Rating. A rating of 4 or 5 can be cosnidered as a positive review. A rating of 1 or 2 can be considered as negative one. A review of rating 3 is considered nuetral and such reviews are ignored from our analysis. This is an approximate and proxy way of determining the polarity (positivity/negativity) of a review.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1] Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1.1]  Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chauh\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3 as sql\n",
    "import seaborn as sns\n",
    "import random\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con = sql.connect('D:/Work/database.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525814, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = pd.read_sql_query(\"\"\"select * from Reviews where Score != 3\"\"\", con)\n",
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual_score = filtered_data['Score']\n",
    "posneg = actual_score.map(partition)\n",
    "filtered_data['Score'] = posneg\n",
    "\n",
    "sorted_data = filtered_data.sort_values('ProductId', axis=0, ascending= True, inplace= False, kind= 'quicksort', na_position='last')\n",
    "final = sorted_data.drop_duplicates(subset={'UserId', 'ProfileName', 'Time', 'Text'}, keep='first', inplace=False)\n",
    "\n",
    "final = final[final.HelpfulnessNumerator <= final.HelpfulnessDenominator]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3] Pre processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3.1] Processing review text\n",
    "\n",
    "Now that we have finished deduplication our data requires some preprocessing before we go on further with analysis and making the prediction model.\n",
    "\n",
    "Hence in the Preprocessing phase we do the following in the order below:-\n",
    "\n",
    "1. Begin by removing the html tags\n",
    "2. Remove any punctuations or limited set of special characters like , or . or # etc.\n",
    "3. Check if the word is made up of english letters and is not alpha-numeric\n",
    "4. Check to see if the length of the word is greater than 2 (as it was researched that there is no adjective in 2-letters)\n",
    "5. Convert the word to lowercase\n",
    "6. Remove Stopwords\n",
    "7. Finally Snowball Stemming the word (it was obsereved to be better than Porter Stemming)<br>\n",
    "\n",
    "After which we collect the words used to describe positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "I set aside at least an hour each day to read to my son (3 y/o). At this point, I consider myself a connoisseur of children's books and this is one of the best. Santa Clause put this under the tree. Since then, we've read it perpetually and he loves it.<br /><br />First, this book taught him the months of the year.<br /><br />Second, it's a pleasure to read. Well suited to 1.5 y/o old to 4+.<br /><br />Very few children's books are worth owning. Most should be borrowed from the library. This book, however, deserves a permanent spot on your shelf. Sendak's best.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "i=0\n",
    "for sent in final['Text'].values:\n",
    "    if len(re.findall('<.*?',sent)):\n",
    "        print(i)\n",
    "        print(sent)\n",
    "        break\n",
    "    i += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'your', 'to', 'both', 'll', 're', 'so', 'can', 'where', 'from', 'weren', \"wouldn't\", 'off', 'had', 'having', 'over', 'themselves', 'me', 'should', 'yourselves', 'here', 'o', 'herself', 'once', 'through', 'as', 'of', 'this', 'haven', 'just', 'won', 'same', 'shouldn', 'very', \"shan't\", 'above', 'be', \"didn't\", 'been', 'why', 'ourselves', 'will', 'hadn', 'we', \"doesn't\", 'am', 'by', 'such', 'couldn', 'other', \"you've\", 'no', 's', 'his', \"should've\", \"haven't\", 'into', 'ain', \"mustn't\", 'if', 'my', 'any', 'doing', \"you're\", 'those', 'each', 'being', 'after', 'now', 'but', 'between', \"you'd\", 'in', 'ma', 'for', 'its', \"shouldn't\", 'itself', 'yourself', 'were', 'm', 'isn', 'some', 'myself', 'have', 'too', 'most', 'during', 'him', \"aren't\", 'hers', 'you', 'while', 'all', 'further', 'out', \"won't\", 'himself', \"wasn't\", \"hasn't\", 'not', 'aren', 'whom', 'does', 'are', \"couldn't\", 'below', 'i', 'and', \"don't\", 'then', 'is', 'a', 'it', 'didn', 'nor', 'an', 'at', 'against', 'wasn', 'few', \"you'll\", 't', 'before', \"isn't\", 'hasn', 'these', 'mustn', 'her', 'needn', 'don', 'he', 'doesn', 'wouldn', 'more', 'do', 'who', 'how', 'up', \"that'll\", \"weren't\", 'on', \"it's\", 'only', 'has', 'the', 'she', 'because', 'shan', 'there', 'under', 'again', 'they', 'with', 've', 'when', 'y', 'what', \"needn't\", 'yours', 'ours', 'own', 'theirs', \"she's\", 'mightn', 'd', \"hadn't\", 'down', 'was', 'did', 'until', 'our', 'them', 'about', 'or', 'that', 'their', 'which', \"mightn't\", 'than'}\n"
     ]
    }
   ],
   "source": [
    "stop = set(stopwords.words('english')) #set of stopwords\n",
    "sno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n",
    "\n",
    "def cleanhtml(sentence): #function to clean the word of any html-tags\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "str1=' '\n",
    "final_string=[]\n",
    "all_positive_words=[] # store words from +ve reviews here\n",
    "all_negative_words=[] # store words from -ve reviews here.\n",
    "s=''\n",
    "for sent in final['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "    #print(sent)\n",
    "    sent=cleanhtml(sent) # remove HTMl tags\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
    "                if(cleaned_words.lower() not in stop):\n",
    "                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                    filtered_sentence.append(s)\n",
    "                    if (final['Score'].values)[i] == 'positive': \n",
    "                        all_positive_words.append(s) #list of all words used to describe positive reviews\n",
    "                    if(final['Score'].values)[i] == 'negative':\n",
    "                        all_negative_words.append(s) #list of all words used to describe negative reviews reviews\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue \n",
    "    #print(filtered_sentence)\n",
    "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n",
    "    #print(\"***********************************************************************\")\n",
    "    \n",
    "    final_string.append(str1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final['CleanedText']=final_string\n",
    "final['CleanedText']=final['CleanedText'].str.decode(\"utf-8\")\n",
    "conn = sql.connect('final.sqlite')\n",
    "c=conn.cursor()\n",
    "conn.text_factory = str\n",
    "final.to_sql('Reviews', conn,  schema=None, if_exists='replace', index=True, index_label=None, chunksize=None, dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 11)\n"
     ]
    }
   ],
   "source": [
    "# down sampling to make the dataset balanced.\n",
    "pos = final[final['Score']=='positive'].sample(n = 50000 )\n",
    "neg = final[final['Score']=='negative'].sample(n = 50000)\n",
    "final_ = pd.concat([pos,neg])\n",
    "print(final_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_sorted = final_.sort_values(by=['Time'], ascending=True)\n",
    "data_sorted = data_sorted[['Id','ProductId','UserId','ProfileName','HelpfulnessNumerator','HelpfulnessDenominator','Time','Summary','Text','CleanedText','Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data_sorted['CleanedText'].values, data_sorted['Score'].values, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3] Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3.1] Bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 5000)\n",
      "(30000, 5000)\n"
     ]
    }
   ],
   "source": [
    "#unigram\n",
    "count_vect = CountVectorizer(max_features=5000)\n",
    "X_tr = count_vect.fit_transform(X_train)\n",
    "X_te = count_vect.transform(X_test)\n",
    "\n",
    "#standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler(copy=True, with_mean=False, with_std=True)\n",
    "X_tra = std.fit_transform(X_tr)\n",
    "X_tes = std.transform(X_te)\n",
    "\n",
    "print(X_tra.shape)\n",
    "print(X_tes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc, make_scorer\n",
    "def custom_auc(ground_truth, predictions):\n",
    "    fpr, tpr, _ = roc_curve(ground_truth, predictions[:, 1], pos_label='positive')    \n",
    "    return auc(fpr, tpr)\n",
    "\n",
    "auc_ = make_scorer(custom_auc, greater_is_better=True, needs_proba=True)\n",
    "\n",
    "c = [0.001,0.01,0.1,1,10,100,1000] # hyper parameter\n",
    "reg = ['l1','l2']\n",
    "dict = {}\n",
    "for i in c:\n",
    "    for j in reg:\n",
    "        clf = LogisticRegression(C=i,penalty=j)\n",
    "        scores = cross_val_score(clf, X_tra, Y_train, scoring=auc_)\n",
    "        dict[i,j] = max(scores)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value of hyper parameter is  (0.01, 'l1')\n",
      "The best score is  0.939854331374\n"
     ]
    }
   ],
   "source": [
    "#print(dict)\n",
    "import operator\n",
    "c_ = max(dict.items(), key=operator.itemgetter(1))[0]\n",
    "max_auc_score = dict[c_]\n",
    "print('The best value of hyper parameter is ', c_)\n",
    "print('The best score is ', max_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.87%\n",
      "Precision on test set: 0.87%\n",
      "Recall on test set: 0.88%\n",
      "F1 score on test set: 0.88%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD8CAYAAAC8TPVwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22c062cdb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#training the model with best value of hyper parameter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(C=0.01,penalty='l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "y_pred = clf.predict(X_tes)\n",
    "\n",
    "import seaborn as sns\n",
    "ax = sns.heatmap(confusion_matrix(Y_test, y_pred), annot=True, fmt='d')\n",
    "\n",
    "print('Accuracy on test set: %0.2f%%'%(accuracy_score(Y_test, y_pred)))\n",
    "print('Precision on test set: %0.2f%%'%(precision_score(Y_test, y_pred, pos_label='positive')))\n",
    "print('Recall on test set: %0.2f%%'%(recall_score(Y_test, y_pred, pos_label='positive')))\n",
    "print('F1 score on test set: %0.2f%%'%(f1_score(Y_test, y_pred, pos_label='positive')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tPositive\t\t\t\t\t\tNegative\n",
      "________________________________________________________________________________________________\n",
      "\t-0.7807\taccomplish     \t\t\t\t0.6250\tafghanistan    \n",
      "\t-0.4012\tador           \t\t\t\t0.4608\talfredo        \n",
      "\t-0.3708\tacquir         \t\t\t\t0.3999\taftertast      \n",
      "\t-0.3623\taid            \t\t\t\t0.3816\taccur          \n",
      "\t-0.3501\tairi           \t\t\t\t0.3726\taggress        \n",
      "\t-0.2458\tala            \t\t\t\t0.2824\tactual         \n",
      "\t-0.2426\tadvic          \t\t\t\t0.2789\tairport        \n",
      "\t-0.2326\tahead          \t\t\t\t0.2678\tacai           \n",
      "\t-0.2315\tadjust         \t\t\t\t0.2531\talcohol        \n",
      "\t-0.2236\taggrav         \t\t\t\t0.2414\tabandon        \n"
     ]
    }
   ],
   "source": [
    "def show_most_informative_features(vectorizer, clf, n=10):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    print(\"\\t\\t\\tPositive\\t\\t\\t\\t\\t\\tNegative\")\n",
    "    print(\"________________________________________________________________________________________________\")\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        print(\"\\t%.4f\\t%-15s\\t\\t\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))\n",
    "        \n",
    "show_most_informative_features(count_vect,clf)\n",
    "#Code Reference:https://stackoverflow.com/questions/11116697/how-to-get-most-informative-features-for-scikit-learn-classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsity using L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 4999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 100, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 4991\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 10, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 4939\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 1, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 4480\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 0.1, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 1972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 0.01, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 153\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 0.001, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pertubation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 1983\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(C=0.01,penalty='l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "y_pred = clf.predict(X_tes)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01281491  0.          0.         ...,  0.         -0.01395659  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#weights as of now\n",
    "#from scipy.sparse import find\n",
    "w1 = clf.coef_\n",
    "#w1 = find(clf.coef_[0])[2]\n",
    "print(w1[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import find\n",
    "X_tra_noise = X_tra\n",
    "eps = np.random.uniform(low=-0.0001, high=0.0001, size=(find(X_tra_noise)[0].size,)) #noise\n",
    "\n",
    "#Getting the postions(row and column) and value of non-zero datapoints \n",
    "a,b,c = find(X_tra_noise)\n",
    "\n",
    "#adding noise to non-zero datapoints\n",
    "X_tra_noise[a,b] = eps + X_tra_noise[a,b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 1982\n"
     ]
    }
   ],
   "source": [
    "#training with noise\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 0.01, penalty= 'l1')\n",
    "clf.fit(X_tra_noise,Y_train)\n",
    "y_pred = clf.predict(X_tes)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01281507  0.          0.         ...,  0.         -0.01395966  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#weights after adding noise\n",
    "w2 = clf.coef_\n",
    "#w2 = find(clf.coef_[0])[2]\n",
    "print(w2[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1 += 10**-6\n",
    "w2 += 10**-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00128038  0.          0.         ...,  0.          0.02201433  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#percentage difference\n",
    "change = (abs((w1-w2)/w1))*100\n",
    "print(change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3.2] TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 32460)\n",
      "(30000, 32460)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "X_tr = tfidf_vect.fit_transform(X_train)\n",
    "X_te = tfidf_vect.transform(X_test)\n",
    "\n",
    "#standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler(copy=True, with_mean=False, with_std=True)\n",
    "\n",
    "X_tra = std.fit_transform(X_tr)\n",
    "X_tes = std.transform(X_te)\n",
    "\n",
    "print(X_tra.shape)\n",
    "print(X_tes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc, make_scorer\n",
    "def custom_auc(ground_truth, predictions):\n",
    "    fpr, tpr, _ = roc_curve(ground_truth, predictions[:, 1], pos_label='positive')    \n",
    "    return auc(fpr, tpr)\n",
    "\n",
    "auc_ = make_scorer(custom_auc, greater_is_better=True, needs_proba=True)\n",
    "\n",
    "c = [0.001,0.01,0.1,1,10,100,1000] # hyper parameter\n",
    "reg = ['l1','l2']\n",
    "dict = {}\n",
    "for i in c:\n",
    "    for j in reg:\n",
    "        clf = LogisticRegression(C=i,penalty=j)\n",
    "        scores = cross_val_score(clf, X_tra, Y_train, scoring=auc_)\n",
    "        dict[i,j] = max(scores)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value of hyper parameter is  (0.01, 'l1')\n",
      "The best score is  0.94709407512\n"
     ]
    }
   ],
   "source": [
    "#print(dict)\n",
    "import operator\n",
    "c_ = max(dict.items(), key=operator.itemgetter(1))[0]\n",
    "max_auc_score = dict[c_]\n",
    "print('The best value of hyper parameter is ', c_)\n",
    "print('The best score is ', max_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.87%\n",
      "Precision on test set: 0.87%\n",
      "Recall on test set: 0.88%\n",
      "F1 score on test set: 0.88%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD8CAYAAAC8TPVwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28c8084c9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#training the model with best value of hyper parameter\n",
    "clf = LogisticRegression(C=0.01,penalty='l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "y_pred = clf.predict(X_tes)\n",
    "\n",
    "import seaborn as sns\n",
    "ax = sns.heatmap(confusion_matrix(Y_test, y_pred), annot=True, fmt='d')\n",
    "\n",
    "print('Accuracy on test set: %0.2f%%'%(accuracy_score(Y_test, y_pred)))\n",
    "print('Precision on test set: %0.2f%%'%(precision_score(Y_test, y_pred, pos_label='positive')))\n",
    "print('Recall on test set: %0.2f%%'%(recall_score(Y_test, y_pred, pos_label='positive')))\n",
    "print('F1 score on test set: %0.2f%%'%(f1_score(Y_test, y_pred, pos_label='positive')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tPositive\t\t\t\t\t\tNegative\n",
      "________________________________________________________________________________________________\n",
      "\t-0.4325\tdisappoint     \t\t\t\t0.6075\tgreat          \n",
      "\t-0.3425\tworst          \t\t\t\t0.4587\tlove           \n",
      "\t-0.2923\tterribl        \t\t\t\t0.4316\tbest           \n",
      "\t-0.2554\treturn         \t\t\t\t0.3784\tdelici         \n",
      "\t-0.2530\thorribl        \t\t\t\t0.3170\tperfect        \n",
      "\t-0.2501\taw             \t\t\t\t0.3127\tgood           \n",
      "\t-0.2026\tunfortun       \t\t\t\t0.2876\texcel          \n",
      "\t-0.1994\ttast           \t\t\t\t0.2134\tnice           \n",
      "\t-0.1853\tdisgust        \t\t\t\t0.2126\tfavorit        \n",
      "\t-0.1820\twast           \t\t\t\t0.2076\tamaz           \n"
     ]
    }
   ],
   "source": [
    "def show_most_informative_features(vectorizer, clf, n=10):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    print(\"\\t\\t\\tPositive\\t\\t\\t\\t\\t\\tNegative\")\n",
    "    print(\"________________________________________________________________________________________________\")\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        print(\"\\t%.4f\\t%-15s\\t\\t\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))\n",
    "        \n",
    "show_most_informative_features(tfidf_vect,clf)\n",
    "#Code Reference:https://stackoverflow.com/questions/11116697/how-to-get-most-informative-features-for-scikit-learn-classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsity check with L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 26683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 1000, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 25701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 100, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 24166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 10, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 21804\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 1, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 17705\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 0.1, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 6782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 0.01, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 171\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 0.001, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pertubation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 6663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(C=0.01,penalty='l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "y_pred = clf.predict(X_tes)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.         -0.00133931 ...,  0.          0.          0.00023088]]\n"
     ]
    }
   ],
   "source": [
    "#weights as of now\n",
    "#from scipy.sparse import find\n",
    "w1 = clf.coef_\n",
    "#w1 = find(clf.coef_[0])[2]\n",
    "print(w1[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tra_noise = X_tra\n",
    "#eps = np.random.uniform(low=-0.0001, high=0.0001, size = X_tra_noise[0].size)\n",
    "eps = np.random.uniform(low=-0.0001, high=0.0001, size=(find(X_tra_noise)[0].size,)) #noise\n",
    "#Getting the postions(row and column) and value of non-zero datapoints \n",
    "a,b,c = find(X_tra_noise)\n",
    "#adding noise to non-zero datapoints\n",
    "X_tra_noise[a,b] = eps + X_tra_noise[a,b]\n",
    "#X_tra_noise = eps + X_tra_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 6669\n"
     ]
    }
   ],
   "source": [
    "#training with noise\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 0.01, penalty= 'l1')\n",
    "clf.fit(X_tra_noise,Y_train)\n",
    "y_pred = clf.predict(X_tes)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.         -0.00133638 ...,  0.          0.          0.00091567]]\n"
     ]
    }
   ],
   "source": [
    "#weights after adding noise\n",
    "w2 = clf.coef_\n",
    "#w2 = find(clf.coef_[0])[2]\n",
    "print(w2[:50])\n",
    "#print(w2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1 += 10**-6\n",
    "w2 += 10**-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10561386.2488\n"
     ]
    }
   ],
   "source": [
    "#percentage difference\n",
    "change = (np.sum(abs((w1-w2)/w1)))*100\n",
    "print(change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training own Word2Vec model using your own train text corpus\n",
    "import gensim\n",
    "list_of_sent=[]\n",
    "\n",
    "for sent in X_train:\n",
    "    filtered_sentence=[]\n",
    "    for word in sent.split():\n",
    "        for cleaned_words in cleanpunc(word).split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower())\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent.append(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model=gensim.models.Word2Vec(list_of_sent,min_count=5,size=100, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_words = list(w2v_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_sent_test = []\n",
    "for sent in X_test:\n",
    "    filtered_sentence=[]\n",
    "    for word in sent.split():\n",
    "        for cleaned_words in cleanpunc(word).split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower())\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent_test.append(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avg W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_vectors_TRAIN = []; \n",
    "for sent in list_of_sent: \n",
    "    sent_vec = np.zeros(100)\n",
    "    cnt_words =0; \n",
    "    for word in sent: \n",
    "        if word in w2v_words:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        sent_vec /= cnt_words\n",
    "    sent_vectors_TRAIN.append(sent_vec)\n",
    "\n",
    "sent_vectors_TEST = []; \n",
    "for sent in list_of_sent_test: \n",
    "    sent_vec = np.zeros(100)\n",
    "    cnt_words =0; \n",
    "    for word in sent: \n",
    "        if word in w2v_words:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        sent_vec /= cnt_words\n",
    "    sent_vectors_TEST.append(sent_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 100)\n",
      "(30000, 100)\n"
     ]
    }
   ],
   "source": [
    "#standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler(copy=True, with_mean=False, with_std=True)\n",
    "\n",
    "X_tra = std.fit_transform(sent_vectors_TRAIN)\n",
    "X_tes = std.transform(sent_vectors_TEST)\n",
    "\n",
    "print(X_tra.shape)\n",
    "print(X_tes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc, make_scorer\n",
    "def custom_auc(ground_truth, predictions):\n",
    "    fpr, tpr, _ = roc_curve(ground_truth, predictions[:, 1], pos_label='positive')    \n",
    "    return auc(fpr, tpr)\n",
    "\n",
    "auc_ = make_scorer(custom_auc, greater_is_better=True, needs_proba=True)\n",
    "\n",
    "c = [0.001,0.01,0.1,1,10,100,1000] # hyper parameter\n",
    "reg = ['l1','l2']\n",
    "dict = {}\n",
    "for i in c:\n",
    "    for j in reg:\n",
    "        clf = LogisticRegression(C=i,penalty=j)\n",
    "        scores = cross_val_score(clf, X_tra, Y_train, scoring=auc_)\n",
    "        dict[i,j] = max(scores)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value of hyper parameter is  (0.1, 'l1')\n",
      "The best score is  0.923644673862\n"
     ]
    }
   ],
   "source": [
    "#print(dict)\n",
    "import operator\n",
    "c_ = max(dict.items(), key=operator.itemgetter(1))[0]\n",
    "max_auc_score = dict[c_]\n",
    "print('The best value of hyper parameter is ', c_)\n",
    "print('The best score is ', max_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.85%\n",
      "Precision on test set: 0.86%\n",
      "Recall on test set: 0.84%\n",
      "F1 score on test set: 0.85%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD8CAYAAAC8TPVwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1db2a33bd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#training the model with best value of hyper parameter\n",
    "clf = LogisticRegression(C=0.1,penalty='l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "y_pred = clf.predict(X_tes)\n",
    "\n",
    "import seaborn as sns\n",
    "ax = sns.heatmap(confusion_matrix(Y_test, y_pred), annot=True, fmt='d')\n",
    "\n",
    "print('Accuracy on test set: %0.2f%%'%(accuracy_score(Y_test, y_pred)))\n",
    "print('Precision on test set: %0.2f%%'%(precision_score(Y_test, y_pred, pos_label='positive')))\n",
    "print('Recall on test set: %0.2f%%'%(recall_score(Y_test, y_pred, pos_label='positive')))\n",
    "print('F1 score on test set: %0.2f%%'%(f1_score(Y_test, y_pred, pos_label='positive')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 1000, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 100, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 10, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 1, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 0.1, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 0.01, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 38\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 0.001, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pertubation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(C=0.1,penalty='l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "y_pred = clf.predict(X_tes)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.18158631  0.38119818 -0.09202783 -0.07280273 -0.19755169  0.21496575\n",
      "  -0.64489484  0.20795525  0.17232091 -0.04112043 -0.01664352 -0.13655291\n",
      "   0.00899827  0.10702985  0.30598386 -0.13418279  0.46211364  0.06027384\n",
      "   0.44568433  0.11333529 -0.26340398  0.1442699   0.15847305 -0.08701019\n",
      "   0.0868698   0.60098747 -0.26132705  0.12207499 -0.07638939  0.41730211\n",
      "   0.14627892  0.34097224  0.15905488  0.19227353 -0.34336696 -0.34050458\n",
      "  -0.18115796  0.24595999  0.21170464 -0.42619317  0.10844331  0.1660308\n",
      "  -0.11335034  0.20127913 -0.08372807 -0.03587241  0.08649826 -0.35402089\n",
      "  -0.14737472  0.18137868 -0.07596315  0.1393826   0.17670217 -0.23495009\n",
      "  -0.10332862 -0.03778506  0.0019195   0.30256063  0.05624048  0.14614739\n",
      "  -0.19764969  0.23365352  0.          0.05402262  0.35195357 -0.03327357\n",
      "   0.01133252 -0.14470742 -0.0697396   0.03274746  0.16604023 -0.1909839\n",
      "  -0.0417343   0.15996682  0.10433504 -0.11667993 -0.19164354 -0.04652345\n",
      "   0.17114517  0.35356508 -0.13221579 -0.43981646  0.06399263 -0.12737645\n",
      "   0.07274048  0.02621131  0.18515549 -0.14035184  0.23022963 -0.06767861\n",
      "   0.03051151  0.07854888  0.09346702  0.24304277 -0.04616882  0.21735618\n",
      "   0.10704361  0.12215169 -0.08535638  0.08026537]]\n"
     ]
    }
   ],
   "source": [
    "#weights as of now\n",
    "#from scipy.sparse import find\n",
    "w1 = clf.coef_\n",
    "#w1 = find(clf.coef_[0])[2]\n",
    "print(w1[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tra_noise = X_tra\n",
    "eps = np.random.uniform(low=-0.0001, high=0.0001, size=(find(X_tra_noise)[0].size,)) #noise\n",
    "#Getting the postions(row and column) and value of non-zero datapoints \n",
    "a,b,c = find(X_tra_noise)\n",
    "\n",
    "#adding noise to non-zero datapoints\n",
    "X_tra_noise[a,b] = eps + X_tra_noise[a,b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 99\n"
     ]
    }
   ],
   "source": [
    "#training with noise\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 0.1, penalty= 'l1')\n",
    "clf.fit(X_tra_noise,Y_train)\n",
    "y_pred = clf.predict(X_tes)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.18252952  0.38205685 -0.09217313 -0.07287893 -0.19799611  0.2140811\n",
      "  -0.64564881  0.20801356  0.17243406 -0.04119817 -0.01282879 -0.13707193\n",
      "   0.00814292  0.10724993  0.30507217 -0.13214768  0.4623082   0.06005151\n",
      "   0.44559401  0.11296866 -0.2644223   0.14354152  0.15868571 -0.0870517\n",
      "   0.08717443  0.60096739 -0.26147338  0.12137926 -0.07736252  0.41800545\n",
      "   0.14658514  0.34142445  0.15878385  0.19253179 -0.34261884 -0.34092738\n",
      "  -0.18099852  0.24701538  0.2122671  -0.4259079   0.10861525  0.16698056\n",
      "  -0.11425177  0.20141171 -0.08254602 -0.03597477  0.08669084 -0.35404432\n",
      "  -0.14765196  0.1816485  -0.07584045  0.14022324  0.17635344 -0.23486112\n",
      "  -0.10395466 -0.03790181  0.00109785  0.30223499  0.05666679  0.14659223\n",
      "  -0.19757293  0.23369665  0.          0.05413219  0.35188394 -0.03309335\n",
      "   0.01134001 -0.14483555 -0.06953758  0.03208529  0.1661607  -0.19124963\n",
      "  -0.0416257   0.16063381  0.10550848 -0.11635489 -0.19146078 -0.04576992\n",
      "   0.17088263  0.3538584  -0.1328382  -0.43893991  0.06387703 -0.12680545\n",
      "   0.07261439  0.02585786  0.18455627 -0.14050602  0.22994838 -0.06717813\n",
      "   0.02970938  0.07804859  0.09289134  0.2422038  -0.04606938  0.21789478\n",
      "   0.10738097  0.12211586 -0.08537625  0.07975664]]\n"
     ]
    }
   ],
   "source": [
    "#weights after adding noise\n",
    "w2 = clf.coef_\n",
    "#w2 = find(clf.coef_[0])[2]\n",
    "print(w2[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1 += 1e-6\n",
    "w2 += 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.5164957086\n"
     ]
    }
   ],
   "source": [
    "#percentage difference\n",
    "diff = abs(w1 - w2)\n",
    "change = np.sum(diff/w1)*100\n",
    "print(change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF weighted W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "final_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "\n",
    "tfidf_feat = tfidf_vect.get_feature_names()\n",
    "\n",
    "tfidf_sent_vectors_tr = []\n",
    "row=0\n",
    "for sent in list_of_sent: \n",
    "    sent_vec = np.zeros(100) \n",
    "    weight_sum =0\n",
    "    for word in sent:\n",
    "        if word in w2v_words:\n",
    "            vec = w2v_model.wv[word]\n",
    "            tf_idf = final_tfidf[row, tfidf_feat.index(word)]\n",
    "            sent_vec += (vec * tf_idf)\n",
    "            weight_sum += tf_idf\n",
    "    if weight_sum != 0:\n",
    "        sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors_tr.append(sent_vec)\n",
    "    row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_sent_vectors_TEST = [];\n",
    "row=0\n",
    "for sent in list_of_sent_test:  \n",
    "    sent_vec = np.zeros(100) \n",
    "    weight_sum =0\n",
    "    for word in sent: \n",
    "        if word in w2v_words:\n",
    "            vec = w2v_model.wv[word]\n",
    "            tf_idf = final_tfidf[row, tfidf_feat.index(word)]\n",
    "            sent_vec += (vec * tf_idf)\n",
    "            weight_sum += tf_idf\n",
    "    if weight_sum != 0:\n",
    "        sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors_TEST.append(sent_vec)\n",
    "    row += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 100)\n",
      "(30000, 100)\n"
     ]
    }
   ],
   "source": [
    "#standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler(copy=True, with_mean=False, with_std=True)\n",
    "\n",
    "X_tra = std.fit_transform(sent_vectors_TRAIN)\n",
    "X_tes = std.transform(sent_vectors_TEST)\n",
    "\n",
    "print(X_tra.shape)\n",
    "print(X_tes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc, make_scorer\n",
    "def custom_auc(ground_truth, predictions):\n",
    "    fpr, tpr, _ = roc_curve(ground_truth, predictions[:, 1], pos_label='positive')    \n",
    "    return auc(fpr, tpr)\n",
    "\n",
    "auc_ = make_scorer(custom_auc, greater_is_better=True, needs_proba=True)\n",
    "\n",
    "c = [0.001,0.01,0.1,1,10,100,1000] # hyper parameter\n",
    "reg = ['l1','l2']\n",
    "dict = {}\n",
    "for i in c:\n",
    "    for j in reg:\n",
    "        clf = LogisticRegression(C=i,penalty=j)\n",
    "        scores = cross_val_score(clf, X_tra, Y_train, scoring=auc_)\n",
    "        dict[i,j] = max(scores)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value of hyper parameter is  (0.1, 'l1')\n",
      "The best score is  0.92364431382\n"
     ]
    }
   ],
   "source": [
    "#print(dict)\n",
    "import operator\n",
    "c_ = max(dict.items(), key=operator.itemgetter(1))[0]\n",
    "max_auc_score = dict[c_]\n",
    "print('The best value of hyper parameter is ', c_)\n",
    "print('The best score is ', max_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.85%\n",
      "Precision on test set: 0.86%\n",
      "Recall on test set: 0.84%\n",
      "F1 score on test set: 0.85%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD8CAYAAAC8TPVwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1db32092a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#training the model with best value of hyper parameter\n",
    "clf = LogisticRegression(C=0.1,penalty='l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "y_pred = clf.predict(X_tes)\n",
    "\n",
    "import seaborn as sns\n",
    "ax = sns.heatmap(confusion_matrix(Y_test, y_pred), annot=True, fmt='d')\n",
    "\n",
    "print('Accuracy on test set: %0.2f%%'%(accuracy_score(Y_test, y_pred)))\n",
    "print('Precision on test set: %0.2f%%'%(precision_score(Y_test, y_pred, pos_label='positive')))\n",
    "print('Recall on test set: %0.2f%%'%(recall_score(Y_test, y_pred, pos_label='positive')))\n",
    "print('F1 score on test set: %0.2f%%'%(f1_score(Y_test, y_pred, pos_label='positive')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 1000, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 100, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 10, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 1, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 0.1, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 0.01, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 38\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 0.001, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 0.0001, penalty= 'l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pertubation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(C=0.1,penalty='l1')\n",
    "clf.fit(X_tra,Y_train)\n",
    "y_pred = clf.predict(X_tes)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.18223168  0.38221252 -0.0920652  -0.07282922 -0.19702009  0.21465219\n",
      "  -0.64489108  0.20801944  0.17223961 -0.04107001 -0.01392369 -0.1366491\n",
      "   0.00894116  0.10717701  0.30568782 -0.1335935   0.46110311  0.05968478\n",
      "   0.44543751  0.11270381 -0.26394702  0.14368283  0.15851288 -0.08691142\n",
      "   0.08689471  0.60101595 -0.26097858  0.12285286 -0.0767456   0.41809561\n",
      "   0.14606642  0.34083519  0.15888527  0.19235032 -0.34291363 -0.34072884\n",
      "  -0.18085789  0.24567931  0.21165005 -0.42569402  0.10874061  0.16631364\n",
      "  -0.11382886  0.20161458 -0.08303451 -0.03576965  0.08665644 -0.35360424\n",
      "  -0.14728156  0.18199813 -0.07605339  0.13945516  0.177001   -0.23490367\n",
      "  -0.10417024 -0.03785996  0.00150955  0.30231244  0.05654073  0.14697502\n",
      "  -0.19762291  0.23333842  0.          0.05416984  0.35200829 -0.03309625\n",
      "   0.01193504 -0.1445059  -0.06964518  0.03268704  0.16611809 -0.19086924\n",
      "  -0.04195351  0.1606357   0.10542183 -0.11655337 -0.19130028 -0.04597737\n",
      "   0.17099587  0.354102   -0.13261705 -0.43984376  0.06395096 -0.1272518\n",
      "   0.07279984  0.02631555  0.18474854 -0.14045354  0.228797   -0.06758889\n",
      "   0.0306788   0.07801081  0.09332348  0.24233581 -0.04625523  0.21764206\n",
      "   0.1074158   0.12245652 -0.08548672  0.08048118]]\n"
     ]
    }
   ],
   "source": [
    "#weights as of now\n",
    "#from scipy.sparse import find\n",
    "w1 = clf.coef_\n",
    "#w1 = find(clf.coef_[0])[2]\n",
    "print(w1[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tra_noise = X_tra\n",
    "eps = np.random.uniform(low=-0.0001, high=0.0001, size=(find(X_tra_noise)[0].size,)) #noise\n",
    "#Getting the postions(row and column) and value of non-zero datapoints \n",
    "a,b,c = find(X_tra_noise)\n",
    "\n",
    "#adding noise to non-zero datapoints\n",
    "X_tra_noise[a,b] = eps + X_tra_noise[a,b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero weights: 99\n"
     ]
    }
   ],
   "source": [
    "#training with noise\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C= 0.1, penalty= 'l1')\n",
    "clf.fit(X_tra_noise,Y_train)\n",
    "y_pred = clf.predict(X_tes)\n",
    "print(\"Non Zero weights:\",np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.18126851  0.38082001 -0.09212571 -0.07277266 -0.19730095  0.21490739\n",
      "  -0.64477488  0.20798752  0.17230835 -0.04127824 -0.01770499 -0.13657093\n",
      "   0.00908172  0.10707785  0.30627842 -0.13398352  0.46251303  0.06049351\n",
      "   0.44552357  0.11347736 -0.26303823  0.14427457  0.15837048 -0.08704522\n",
      "   0.0869209   0.60087723 -0.26150073  0.12135094 -0.07624733  0.41714106\n",
      "   0.14634579  0.3408232   0.15914703  0.19224175 -0.34357037 -0.34051218\n",
      "  -0.18134371  0.246241    0.21163787 -0.42641158  0.10836654  0.165838\n",
      "  -0.11332846  0.20119898 -0.08401883 -0.0359514   0.08636915 -0.35397042\n",
      "  -0.1474301   0.18101034 -0.07584167  0.13921938  0.1766419  -0.23499468\n",
      "  -0.10294827 -0.03787529  0.00208052  0.30258686  0.05602757  0.14574431\n",
      "  -0.19753864  0.23386657  0.          0.05399752  0.35188908 -0.03323782\n",
      "   0.01104537 -0.14460001 -0.06979679  0.03275744  0.16598476 -0.19107704\n",
      "  -0.0416593   0.15997905  0.10404817 -0.11673262 -0.19163136 -0.04670805\n",
      "   0.17136427  0.35334917 -0.13200468 -0.43969219  0.06403919 -0.1273519\n",
      "   0.07270517  0.02600912  0.18528027 -0.14017548  0.23082054 -0.0674759\n",
      "   0.03021664  0.07877736  0.09353636  0.24328731 -0.04616602  0.21735924\n",
      "   0.10695778  0.12195824 -0.08541121  0.0800687 ]]\n"
     ]
    }
   ],
   "source": [
    "#weights after adding noise\n",
    "w2 = clf.coef_\n",
    "#w2 = find(clf.coef_[0])[2]\n",
    "print(w2[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1 += 1e-6\n",
    "w2 += 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.3359375802\n"
     ]
    }
   ],
   "source": [
    "#percentage difference\n",
    "diff = abs(w1 - w2)\n",
    "change = (np.sum(diff/w1))*100\n",
    "print(change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
