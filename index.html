<html>
<body>
<h1> Amazon Fine Food Reviews Analysis </h1> <br>

  <h3> Data Source: <a href="https://www.kaggle.com/snap/amazon-fine-food-reviews">https://www.kaggle.com/snap/amazon-fine-food-reviews</a> </h3> <br>

  <h3> EDA: <a href="https://nycdatascience.com/blog/student-works/amazon-fine-foods-visualization/">https://nycdatascience.com/blog/student-works/amazon-fine-foods-visualization/</a> </h3><br>


The Amazon Fine Food Reviews dataset consists of reviews of fine foods from Amazon.<br>

Number of reviews: 568,454<br>
Number of users: 256,059<br>
Number of products: 74,258<br>
Timespan: Oct 1999 - Oct 2012<br>
Number of Attributes/Columns in data: 10 
<br>
  <h3> Attribute Information: </h3>
<br>
1. Id <br>
2. ProductId - unique identifier for the product <br>
3. UserId - unqiue identifier for the user <br>
4. ProfileName <br>
5. HelpfulnessNumerator - number of users who found the review helpful <br>
6. HelpfulnessDenominator - number of users who indicated whether they found the review helpful or not <br>
7. Score - rating between 1 and 5 <br>
8. Time - timestamp for the review <br>
9. Summary - brief summary of the review <br>
10. Text - text of the review <br>


  <h3> Objective: </h3> <br>
Given a review, determine whether the review is positive (rating of 4 or 5) or negative (rating of 1 or 2). <br>

<br>
[Q] How to determine if a review is positive or negative?<br>
<br> 
[Ans] We could use Score/Rating. A rating of 4 or 5 can be cosnidered as a positive review. A rating of 1 or 2 can be considered as negative one. A review of rating 3 is considered nuetral and such reviews are ignored from our analysis. This is an approximate and proxy way of determining the polarity (positivity/negativity) of a review. <br>

<h3> Hence, the following machine learning techniques are applied to this data set to achieve the above objective: <h3> <br>
  <ol>
    <li> <a href = "https://nbviewer.jupyter.org/github/chauhanakash23/Sentiment-analysis-Polarity-of-review-text/blob/master/t-SNE.ipynb">t-SNE(t distribution stochastic neighbourhood embedding </a></li>
    <li> <a href = "https://nbviewer.jupyter.org/github/chauhanakash23/Sentiment-analysis-Polarity-of-review-text/blob/master/KNearestNeighburs.ipynb"> k-Nearest Neighbours</a></li>
    <li> <a href = "https://nbviewer.jupyter.org/github/chauhanakash23/Sentiment-analysis-Polarity-of-review-text/blob/master/Naive-Bayes.ipynb"> Naive Bayes </a> </li>
    <li> <a href = "https://nbviewer.jupyter.org/github/chauhanakash23/Sentiment-analysis-Polarity-of-review-text/blob/master/Logistic-Regression.ipynb" Logistic regression </a> </li>
    <li> <a href = "https://nbviewer.jupyter.org/github/chauhanakash23/Sentiment-analysis-Polarity-of-review-text/blob/master/Support%20Vector%20Classification.ipynb">Support Vector Classification</li>
    <li> <a href = "https://nbviewer.jupyter.org/github/chauhanakash23/Sentiment-analysis-Polarity-of-review-text/blob/master/Decision-Trees.ipynb"> Decision Trees </a> </li>
    <li> <a href = "https://nbviewer.jupyter.org/github/chauhanakash23/Sentiment-analysis-Polarity-of-review-text/blob/master/Bagging%28Random%20Forest%29-Boosting%28Gradient%20Boosting%20Decision%20Trees%29.ipynb">Ensemble models(Bagging-Random Forest and Boosting-Gradient Boosting Decision Trees)</a></li>
    <li> <a href = "https://nbviewer.jupyter.org/github/chauhanakash23/Sentiment-analysis-Polarity-of-review-text/blob/master/Clustering-k%20means-hierarchical-DBSCAN.ipynb">Clustering(k-means, hierarchical, density based)</a></li>
    <li> <a href = "https://nbviewer.jupyter.org/github/chauhanakash23/Sentiment-analysis-Polarity-of-review-text/blob/master/Truncated-SVD.ipynb">Truncated Singular Vector Decomposition om co-occurance matrix generated by the words in the review text</a></li>
  </ol>
The following image represents the work flow:

<img src='work.jpg' width=1000px>
